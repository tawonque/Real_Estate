
# coding: utf-8

# # Real Estate competition - Kaggle
# ## We will focus on a random forest model, and a few variations
# 
# ### Let's start by importing the necessary modules

# In[152]:

import os
import numpy as np
import pandas as pd

import sklearn.linear_model as lm
import sklearn.cross_validation as cv
import sklearn.preprocessing as pp
from  sklearn import metrics, tree, grid_search
from sklearn.metrics import confusion_matrix
from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor 

import seaborn as sns
import matplotlib.pyplot as plt

get_ipython().magic('matplotlib inline')


# In[2]:

os.getcwd()


# ### We read the files...

# In[157]:

realestate = pd.read_csv('RealEstate/train.csv')
realestate_test = pd.read_csv('RealEstate/test.csv') 

data_description = open('RealEstate/data_description.txt', 'r')
#print (data_description.read())


# ### Let's examine the columns and get rid of colums (1) with all null values (2) too few values

# In[5]:

realestate.info()
realestate_test.info()

realestate = realestate.dropna(how='all')
realestate_test = realestate_test.dropna(how='all')


#columns withe very few values
few_values = ['Alley', 'PoolQC', 'MiscFeature']
realestate = realestate.drop(few_values, axis=1)
realestate_test = realestate_test.drop(few_values, axis=1)


# In[6]:

print(realestate.info())
print(realestate_test.info())


# ### Let's change the data types of some of the columns too

# In[7]:

#some columns with categorical variables are not 'object'
realestate.MSSubClass.astype('object', inplace=True)
realestate_test.MSSubClass.astype('object', inplace=True)


# ### Some columns could actually be treated as quantitative variables instead of categorical. 
# #### Not strictly necessary, but I wanted to try this little challenge. As you can see I had some issues with in-string variable replacement, so I found a practical solution
# 

# In[8]:

#some columns could be treated as quantitative variables
def change_scale(legend, scale, column_to_replace):
    j = 0
    for i in legend:
        command = column_to_replace + '.replace(to_replace="' + i + '"' + ', value=' + scale[j].astype('str') + ', inplace=True)'
        #print(command)        
        exec(command)
        j += 1
        if j == len(scale):
            break
    return 

legend = ['Ex', 'Gd', 'TA', 'Fa', 'Po']
scale = np.arange(5,0,-1)
column_to_replace = 'realestate.HeatingQC'
change_scale(legend, scale, column_to_replace)
change_scale(legend, scale, 'realestate_test.HeatingQC')

legend = ['Ex', 'Gd', 'TA', 'Fa', 'Po']
scale = np.arange(5,0,-1)
column_to_replace = 'realestate.KitchenQual'
change_scale(legend, scale, column_to_replace)
change_scale(legend, scale, 'realestate_test.KitchenQual')


# ### Separation of the categorical and the quantitative variables

# In[9]:

#Let's separate categorical from quantitative variables and make two dataframes
#Thanks to the kernel by BreadenFitz-Gerald for the idea

df = realestate
categorical = []
for col in df.columns.values:
    if df[col].dtype == 'object':
        categorical.append(col)

df_category = df[categorical]
df_quant = df.drop(categorical, axis=1)

df_category_test = realestate_test[categorical]
df_quant_test = realestate_test.drop(categorical, axis=1)


# ### Correlation coefficients of the quantitative variables
# #### Particularly useful if we do a linear regression, to avoid multicollinearity. In our case, we will go straight ahead with a random forest, but understanding the correlation between variables can be useful when interpreting the variable importance anyway

# In[10]:

#We can calculate the correlation coefficients among variables and flag those with extremely high values
corr = df_quant[df_quant.columns[1:39]].corr()
mask = np.zeros_like(corr)
mask[np.triu_indices_from(mask)] = True

fig = plt.figure(figsize=(20,20))
plt.subplot2grid((1,1), (0,0))
with sns.axes_style("white"):
    ax = sns.heatmap(corr, mask=mask, vmax=.9, square=True, annot=False)


# ### Calculation of the skewness and check for high values that could justify a transformation

# In[11]:

#We can also calculate the skewness and notice that there are many variables
skew = df_quant[df_quant.columns[1:40]].skew()
print(skew)


# In[12]:

df_quant.info()


# In[23]:

#Function to eliminate columns with more than N null values and substitute null values in the remaining with median:
def null_value_treatment(dataframe, thresh_null):
    for col in dataframe.columns.values:
        if np.sum(dataframe[col].isnull()) > thresh_null:
            dataframe.drop(col, axis=1, inplace=True)
        elif np.sum(dataframe[col].isnull()) > 0:
            median = dataframe[col].median()
            idx = np.where(dataframe[col].isnull())[0]
            dataframe[col].iloc[idx] = median
    return

null_value_treatment(df_quant, 150)
null_value_treatment(df_quant_test, 150)


# In[24]:

df_quant.info()


# In[25]:

def transform_skew(dataframe, skew_thresh):
    for col in dataframe.columns.values: 
        if (dataframe[col].skew()) > skew_thresh:
            dataframe[col] = np.log(dataframe[col])
            dataframe[col] = dataframe[col].apply(lambda x: 0 if x == (-1*np.inf) else x)
#           df_quant[col] = Normalizer().fit_transform(df_quant[col].reshape(1,-1))[0]

transform_skew(df_quant, 1.0)
transform_skew(df_quant_test, 1.0)


# In[28]:

def null_value_treatment_categorical(dataframe, thresh_null):
    for col in dataframe.columns.values:
        if np.sum(dataframe[col].isnull()) > thresh_null:
            dataframe.drop(col, axis=1, inplace=True)
        elif np.sum(dataframe[col].isnull()) > 0:
            dataframe[col] = dataframe[col].fillna('MIA', inplace=True)
    return

null_value_treatment_categorical(df_category, 150)
null_value_treatment_categorical(df_category_test, 150)


# In[ ]:

#We can do it as separate loops instead...
'''#Remove columns with too many null values(more then 10% of null data points), transform those with skewness larger than 1. 
#Courtesy of BradenFitz-Gerald

for col in df_quant.columns.values: 
    if np.sum(df_quant[col].isnull()) > 150:
        df_quant = df_quant.drop(col, axis = 1)
    elif np.sum(df_quant[col].isnull()) > 0:
        median = df_quant[col].median()
        idx = np.where(df_quant[col].isnull())[0]
        df_quant[col].iloc[idx] = median
#        outliers = np.where(is_outlier(df_quant[col]))
#        df_quant[col].iloc[outliers] = median
#Which columns for the training set have the conditions above?
#we can do the same loop, eliminating columns with more than xxx of null values
#Let's substitute values... in principle with the median of the test set, but could be alo the median of the training set
for col in df_quant_test.columns.values: 
    if np.sum(df_quant_test[col].isnull()) > 150:
        df_quant_test = df_quant_test.drop(col, axis = 1)    
    elif np.sum(df_quant_test[col].isnull()) > 0:
        median = df_quant_test[col].median()
        idx = np.where(df_quant_test[col].isnull())[0]
        df_quant_test[col].iloc[idx] = median'''
        
'''for col in df_quant.columns.values: 
    if (df_quant[col].skew()) > 1.0:
        df_quant[col] = np.log(df_quant[col])
        df_quant[col] = df_quant[col].apply(lambda x: 0 if x == (-1*np.inf) else x)
#        df_quant[col] = Normalizer().fit_transform(df_quant[col].reshape(1,-1))[0]
#run the same edits for the test set 
for col in df_quant_test.columns.values: 
    if (df_quant_test[col].skew()) > 1.0:
        df_quant_test[col] = np.log(df_quant_test[col])
        df_quant_test[col] = df_quant_test[col].apply(lambda x: 0 if x == (-1*np.inf) else x)'''


# In[ ]:

#Let's edit the categorical variables
'''for col in df_category.columns.values: 
    if np.sum(df_category[col].isnull()) > 150:
        df_category = df_category.drop(col, axis = 1)
    elif np.sum(df_category[col].isnull()) > 0:
        df_category[col] = df_category[col].fillna('MIA')'''


# In[ ]:

'''#Which columns for the training set have the conditions above?
#we can do the same loop, eliminating columns with more than xxx of null values
for col in df_category_test.columns.values: 
    if np.sum(df_category_test[col].isnull()) > 150:
        df_category_test = df_category_test.drop(col, axis = 1)
    elif np.sum(df_category_test[col].isnull()) > 0:
        df_category_test[col] = df_category_test[col].fillna('MIA')'''


# In[29]:

cat_variables = df_category.columns.values
cat_variables_test = df_category_test.columns.values

df_dummies = pd.get_dummies(df_category, columns=cat_variables)
df_dummies_test = pd.get_dummies(df_category_test, columns=cat_variables)


# In[30]:

y_train = df_quant['SalePrice']

X_train = df_dummies.join(df_quant)
X_train = X_train.drop(['SalePrice', 'Id'], axis=1)

X_test = df_dummies_test.join(df_quant_test)
X_test = X_test.drop(['Id'], axis=1)


# In[31]:

X_train.head()


# In[32]:

X_test.head()


# In[33]:

y_train.head()


# ### A Random Forest to start
# #### Ideally, we would fit a linear model with two intentions: (1) Eliminate redundant (collinear) variables (2) assess the importance of each variables. This way, we would have a reference point (and a score) to compare with when doing our Random Forests. 
# #### However, I will skip this step and head straight into the random forest model...

# In[143]:

# Train a random forest with XXX decision trees
model_rf1 = RandomForestRegressor(n_estimators=500)


# In[144]:

#Fit the training data
model_rf1.fit(X_train, y_train)


# #### Let's check the score...

# In[155]:

# Define folds for cross-validation
kf = cv.KFold(1460, n_folds=5, shuffle=True)
#kf = 5
scores = cv.cross_val_score(model_rf1, X_train, y_train, cv=kf)
print(scores, 'and the mean score is =', scores.mean())


# #### Let's investigate the feature importance, possibly eliminating redundant variables, if any

# In[156]:

# Investigate importances of predictors
###model_rf1.feature_importances_
feature_importance = model_rf1.feature_importances_

# make importances relative to max importance
feature_importance = 100.0 * (feature_importance / feature_importance.max())
sorted_idx = np.argsort(feature_importance)
featimp = feature_importance[sorted_idx]
feat = X_train.columns[sorted_idx]
pos = np.arange(sorted_idx.shape[0]) + .5
a = 233 #To limit the number of features
b = 273 - a

plt.figure(figsize=(12, 18))
plt.subplot(1, 1, 1)
plt.barh(pos[a:273], featimp[a:273], align='center')
plt.yticks(pos[a:273], feat[a:273])
plt.xlabel('Relative Importance')
plt.title('Variable Importance (first %s variables)') % b
plt.show()


# In[110]:

#Let's check for a second the names of the columns to be sure what we have...
X_train.columns.values


# In[ ]:

# compute test set deviance
'''test_score = np.zeros((params['n_estimators'],), dtype=np.float64)

for i, y_pred in enumerate(clf.staged_predict(X_test)):
    test_score[i] = clf.loss_(y_test, y_pred)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title('Deviance')
plt.plot(np.arange(params['n_estimators']) + 1, clf.train_score_, 'b-',
         label='Training Set Deviance')
plt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',
         label='Test Set Deviance')
plt.legend(loc='upper right')
plt.xlabel('Boosting Iterations')
plt.ylabel('Deviance')'''


# #### Assess the scores for a few different regressors based on decision trees

# In[ ]:

'''# Investigate importances of predictors
rf1.feature_importances_

# Define folds for cross-validation
kf = cv.KFold(n=10, shuffle=True)

# Cross validation score
mses = cv.cross_val_score(rf1, X, y, scoring='mean_squared_error', cv=kf)
np.mean(-mses)

# Determine ‘optimal’ number of components
gs = grid_search.GridSearchCV(
    estimator=spls,
    param_grid={
        'pls__n_components': np.arange(1, 10)
    },
    scoring='mean_squared_error',
    cv=kf
)
gs.fit(boroughs, feelings)

-gs.best_score_
gs.best_estimator_
gs.grid_scores_
xxxxxxxxxxxxxxxxxxx

confusion_matrix(y_train, model_lr1.predict(X_train))'''
'''
def check_classifiers(X, y):
    """
    Returns a sorted list of accuracy scores from fitting and scoring passed data
    against several algorithms.
    """
    _cv = kf
    classifier_score = {}
    
    scores = cross_val_score(sklearn.ensemble.RandomForestRegressor(), X, y, cv=_cv)
    classifier_score['Random Forest Regressor'] = scores.mean()
    
    scores = cross_val_score(sklearn.ensemble.RandomForestRegressor(), X, y, cv=_cv)
    classifier_score['XXXXKNeighborsClassifier'] = scores.mean()
    
    scores = cross_val_score(sklearn.ensemble.RandomForestRegressor(), X, y, cv=_cv)
    classifier_score['XXXXRandomForestClassifier'] = scores.mean()
    
    scores = cross_val_score(sklearn.ensemble.RandomForestRegressor(), X, y, cv=_cv)
    classifier_score['XXXXSVC'] = scores.mean()
    
    scores = cross_val_score(sklearn.ensemble.RandomForestRegressor(), X, y, cv=_cv)
    classifier_score['XXXXXXGaussianNB'] = scores.mean()

    #return sorted(classifier_score.items(), key=operator.itemgetter(1), reverse=True)
    return sorted(classifier_score.items(), reverse=True)
'''


# #### Select a regressor and perform grid search for selection of best parameters

# #### Evaluate the chosen model

# #### Output the predictions

# In[ ]:



